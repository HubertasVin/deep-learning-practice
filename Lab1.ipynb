{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Hubertas Vindžigalskis, LSP: 2213817, [\"Traffic light\", \"Sandal\", \"Castle\"]"
      ],
      "metadata": {
        "id": "1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2"
      },
      "source": [
        "# Pasiruošimas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3"
      },
      "outputs": [],
      "source": [
        "!pip install openimages\n",
        "import os, glob\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "from openimages.download import download_dataset\n",
        "from PIL import Image\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_ROOT = \"/content/drive/MyDrive/OpenImages\"\n",
        "SAMPLE_LIMIT = 380\n",
        "TARGET_LABELS = [\"Traffic light\", \"Sandal\", \"Strawberry\"]\n",
        "\n",
        "def dataset_exists(root, labels):\n",
        "    return all(os.path.exists(os.path.join(root, lbl.lower())) for lbl in labels)\n",
        "\n",
        "if not dataset_exists(DATA_ROOT, TARGET_LABELS):\n",
        "    download_dataset(DATA_ROOT, TARGET_LABELS, limit=SAMPLE_LIMIT)\n",
        "else:\n",
        "    print(\"Images already downloaded for all classes, skipping download.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5"
      },
      "source": [
        "# Procesoriaus ir modelio paruošimas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "model = models.vgg19(pretrained=True).to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11"
      },
      "source": [
        "# Dataset paruošimas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12"
      },
      "outputs": [],
      "source": [
        "class_dirs = glob.glob(os.path.join(DATA_ROOT, '*'))\n",
        "folder_names = [os.path.basename(folder) for folder in class_dirs]\n",
        "file_paths = [glob.glob(os.path.join(folder, \"images\", \"*\")) for folder in class_dirs]\n",
        "all_files = [fp for sublist in file_paths for fp in sublist]\n",
        "\n",
        "idx_to_class = {i: name for i, name in enumerate(folder_names)}\n",
        "class_to_idx = {name: i for i, name in idx_to_class.items()}\n",
        "print(idx_to_class)\n",
        "print(class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "14"
      },
      "outputs": [],
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, files, transform):\n",
        "        self.files = files\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        fpath = self.files[index]\n",
        "        img = Image.open(fpath)\n",
        "        if img.mode != 'RGB':\n",
        "            img = img.convert('RGB')\n",
        "        img = self.transform(img)\n",
        "\n",
        "        # Extract label from path\n",
        "        lbl = os.path.basename(os.path.dirname(os.path.dirname(fpath)))\n",
        "        return img, class_to_idx[lbl]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])"
      ],
      "metadata": {
        "id": "PegPPPo9T0xW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "15"
      },
      "outputs": [],
      "source": [
        "data = Dataset(all_files, img_transform)\n",
        "loader = DataLoader(data, batch_size=32, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18"
      },
      "source": [
        "# Inference ciklas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "19"
      },
      "outputs": [],
      "source": [
        "gt_all = []      # Ground-truth labels\n",
        "pred_tl = []     # Predictions for \"Traffic light\" (using index 920)\n",
        "pred_sd = []     # Predictions for \"Sandal\" (using index 774)\n",
        "pred_sb = []     # Predictions for \"Strawberry\" (using index 483)\n",
        "\n",
        "for images, labels in loader:\n",
        "    outputs = model(images.to(device))\n",
        "    for i in range(outputs.size(0)):\n",
        "        probs = torch.softmax(outputs[i], dim=0).detach().cpu().numpy()\n",
        "        pred_tl.append(probs[920])\n",
        "        pred_sd.append(probs[774])\n",
        "        pred_sb.append(probs[949])\n",
        "    gt_all.extend(labels.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Konfuzijos matrica ir matavimai"
      ],
      "metadata": {
        "id": "20"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "21"
      },
      "outputs": [],
      "source": [
        "def display_confusion_matrix(class_idx, matrix):\n",
        "    print(\"Class: \", idx_to_class[class_idx])\n",
        "    print(\"-------------------\")\n",
        "    print(\"|   TP   |   FP   |\")\n",
        "    print(\"| {0:^6} | {1:^6} |\".format(matrix['TP'], matrix['FP']))\n",
        "    print(\"|--------|--------|\")\n",
        "    print(\"|   FN   |   TN   |\")\n",
        "    print(\"| {0:^6} | {1:^6} |\".format(matrix['FN'], matrix['TN']))\n",
        "\n",
        "def compute_confusion_matrix(gt, pred, cls, thresh = 0.5):\n",
        "    binary_pred = (np.array(pred) >= thresh).astype(int)\n",
        "    matrix = {\n",
        "        'TP': np.sum((np.array(gt) == cls) & (binary_pred == 1)),\n",
        "        'TN': np.sum((np.array(gt) != cls) & (binary_pred == 0)),\n",
        "        'FP': np.sum((np.array(gt) != cls) & (binary_pred == 1)),\n",
        "        'FN': np.sum((np.array(gt) == cls) & (binary_pred == 0)),\n",
        "    }\n",
        "    display_confusion_matrix(cls, matrix)\n",
        "    return matrix\n",
        "\n",
        "def calculate_metrics(TP, TN, FP, FN):\n",
        "    accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "    recall = TP / (TP + FN) if (TP + FN) else 0\n",
        "    precision = TP / (TP + FP) if (TP + FP) else 0\n",
        "    f1 = 2 * (recall * precision) / (recall + precision) if (recall + precision) else 0\n",
        "    return {'accuracy': accuracy, 'recall': recall, 'precision': precision, 'f1': f1}\n",
        "\n",
        "def show_metrics(mets, cid):\n",
        "    print(\"Class \", idx_to_class[cid], \" metrics:\")\n",
        "    print(\"  accuracy : \", mets['accuracy'])\n",
        "    print(\"  recall : \", mets['recall'])\n",
        "    print(\"  precision : \", mets['precision'])\n",
        "    print(\"  f1 : \", mets['f1'])\n",
        "    print()\n",
        "\n",
        "def show_overall(mets):\n",
        "    print(\"All  metrics:\")\n",
        "    print(\"  accuracy : \", mets['accuracy'])\n",
        "    print(\"  recall : \", mets['recall'])\n",
        "    print(\"  precision : \", mets['precision'])\n",
        "    print(\"  f1 : \", mets['f1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Atliekame skaičiavimus"
      ],
      "metadata": {
        "id": "24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_tl = compute_confusion_matrix(gt_all, pred_tl, 0, thresh=0.05)  # For \"Traffic light\"\n",
        "conf_sd = compute_confusion_matrix(gt_all, pred_sd, 1, thresh=0.05)  # For \"Sandal\"\n",
        "conf_sb = compute_confusion_matrix(gt_all, pred_sb, 2, thresh=0.05)  # For \"Strawberry\"\n",
        "\n",
        "metrics_tl = calculate_metrics(conf_tl['TP'], conf_tl['TN'], conf_tl['FP'], conf_tl['FN'])\n",
        "metrics_sb = calculate_metrics(conf_sb['TP'], conf_sb['TN'], conf_sb['FP'], conf_sb['FN'])\n",
        "metrics_sd = calculate_metrics(conf_sd['TP'], conf_sd['TN'], conf_sd['FP'], conf_sd['FN'])\n",
        "\n",
        "combined_conf = {k: conf_tl[k] + conf_sb[k] + conf_sd[k] for k in ['TP','TN','FP','FN']}\n",
        "metrics_all = calculate_metrics(combined_conf['TP'], combined_conf['TN'], combined_conf['FP'], combined_conf['FN'])\n",
        "\n",
        "show_metrics(metrics_sd, 0)\n",
        "show_metrics(metrics_tl, 1)\n",
        "show_metrics(metrics_sb, 2)\n",
        "show_overall(metrics_all)"
      ],
      "metadata": {
        "id": "25"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}