{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOV3tEgiqmM5DaxIg4/m366",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HubertasVin/deep-learning-practice/blob/main/Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importuojamos reikalingos bibliotekos"
      ],
      "metadata": {
        "id": "iRWxyW2qV9II"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SavZT7mEJteq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da58eab-63dc-4a11-a6a8-830800eaed07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# API imports\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "DATA_DIR = '/content/drive/MyDrive/colab_content'\n",
        "OI_DATA_DIR = DATA_DIR + \"/OpenImages\"\n",
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 60\n",
        "LEARNING_RATE = 1e-4\n",
        "TRAIN_MODE = True\n",
        "NGROK_AUTH_TOKEN = \"2v8l4mW8zOFneFzX7p47qORuEwS_4EcRU64N6iq1mUNEpXN3G\"\n",
        "API_ENABLE = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duomenų įkėlimas ir paruošimas"
      ],
      "metadata": {
        "id": "ojsetMNbV_SW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_paths_and_labels(root_dir):\n",
        "    classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
        "    class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "    for cls in classes:\n",
        "        images_dir = os.path.join(root_dir, cls, \"images\")\n",
        "        if os.path.isdir(images_dir):\n",
        "            for file in os.listdir(images_dir):\n",
        "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    image_paths.append(os.path.join(images_dir, file))\n",
        "                    labels.append(class_to_idx[cls])\n",
        "        else:\n",
        "            print(f\"Warning: {images_dir} not found.\")\n",
        "    return image_paths, labels, classes, class_to_idx\n",
        "\n",
        "image_paths, labels, classes, class_to_idx = get_image_paths_and_labels(OI_DATA_DIR)\n",
        "print(\"Total images:\", len(image_paths))\n",
        "print(\"Classes found:\", classes)\n",
        "\n",
        "# Shuffle and split into training (80%) and validation (20%) sets\n",
        "indices = np.arange(len(image_paths))\n",
        "np.random.shuffle(indices)\n",
        "split = int(0.8 * len(image_paths))\n",
        "train_idx, val_idx = indices[:split], indices[split:]\n",
        "train_paths = [image_paths[i] for i in train_idx]\n",
        "train_labels = [labels[i] for i in train_idx]\n",
        "val_paths   = [image_paths[i] for i in val_idx]\n",
        "val_labels  = [labels[i] for i in val_idx]\n",
        "\n",
        "# Image processing\n",
        "def load_and_preprocess_image(path, label, training=True):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_image(img, channels=3)\n",
        "    img.set_shape([None, None, 3])\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    if training:\n",
        "        img = tf.image.random_flip_left_right(img)\n",
        "    return img, label\n",
        "\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
        "train_ds = train_ds.map(lambda p, l: load_and_preprocess_image(p, l, training=True),\n",
        "                        num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
        "val_ds = val_ds.map(lambda p, l: load_and_preprocess_image(p, l, training=False),\n",
        "                    num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTingvrgV_kB",
        "outputId": "5ca39ee1-9e43-4a3d-e592-d6205afb239a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 1061\n",
            "Classes found: ['sandal', 'strawberry', 'traffic light']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelio kompiliavimas ir treniravimas"
      ],
      "metadata": {
        "id": "1NuOmCoZWEnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SIZE + (3,),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "model_path = os.path.join(DATA_DIR, \"keras_model.h5\")\n",
        "\n",
        "if TRAIN_MODE:\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = keras.Input(shape=IMG_SIZE + (3,))\n",
        "    x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
        "    x = base_model(x, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(len(classes), activation='softmax')(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(\"Phase 1 Training...\")\n",
        "    history1 = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
        "\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:-20]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(\"Phase 2 Training...\")\n",
        "    history2 = model.fit(train_ds, epochs=20, validation_data=val_ds)\n",
        "\n",
        "    # Save the model\n",
        "    model.save(model_path)\n",
        "\n",
        "    # Combine loss values from both phases for plotting\n",
        "    total_epochs = len(history1.history['loss']) + len(history2.history['loss'])\n",
        "    train_loss = history1.history['loss'] + history2.history['loss']\n",
        "    val_loss = history1.history['val_loss'] + history2.history['val_loss']\n",
        "\n",
        "    # Plot the training history\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(range(1, total_epochs + 1), train_loss, label='Training Loss')\n",
        "    plt.plot(range(1, total_epochs + 1), val_loss, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Loading existing model...\")\n",
        "    model = keras.models.load_model(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ_8eLUsWGiK",
        "outputId": "a4657e69-98cb-4c39-c10b-de726f7e5c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 1 Training...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7d6c32f64ea0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/jax/_src/lib/__init__.py\", line 96, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "    \n",
            "KeyboardInterrupt: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nupiešti treniravimo ir validacijos nuostolių grafiką"
      ],
      "metadata": {
        "id": "qWGFtJmlH3do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN_MODE:\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "x_9sEeTQIUu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pagalbinė prognozavimo funkcija"
      ],
      "metadata": {
        "id": "MdcDTr4TWH-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(image):\n",
        "    # Resize and preprocess\n",
        "    img = image.resize(IMG_SIZE)\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
        "    preds = model.predict(img)\n",
        "    pred_class = np.argmax(preds, axis=1)[0]\n",
        "    # index -> class name\n",
        "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "    return idx_to_class.get(pred_class, \"Unknown\")"
      ],
      "metadata": {
        "id": "vx6WpVueIjHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "API skirtas įvesti nuotraukas rankiniu būdu.\n",
        "\n",
        "Nuotraukos testavimui su API:\n",
        "- https://img.freepik.com/free-photo/yummy-strawberries-red-mellow-ripe-with-green-leafs-dark-desk_179666-391.jpg\n",
        "- https://img.freepik.com/free-photo/strawberry-isolated-white-background_1232-1974.jpg\n",
        "- https://img.freepik.com/free-photo/traffic-light-city-streets_23-2149091964.jpg\n",
        "- https://img.freepik.com/free-photo/green-traffic-light-intersection_53876-153444.jpg\n",
        "- https://img.freepik.com/premium-photo/close-up-yellow-street-traffic-light-hanging-from-pole_1048944-23361333.jpg\n",
        "- https://img.freepik.com/free-photo/summer-slipper-white-shoes-sandals_1203-6528.jpg\n",
        "- https://img.freepik.com/premium-photo/close-up-shoes-sand_1048944-30578092.jpg\n",
        "- https://img.freepik.com/free-vector/man-brown-casual-flip-flop-sandal-shoes-vector_53876-25895.jpg"
      ],
      "metadata": {
        "id": "bb177y8FqPlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/test', methods=['GET'])\n",
        "def test_endpoint():\n",
        "    return jsonify({\"message\": \"Test endpoint working!\"}), 200\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if \"file\" in request.files:\n",
        "        file = request.files[\"file\"]\n",
        "        try:\n",
        "            image = tf.keras.preprocessing.image.load_img(file, target_size=IMG_SIZE)\n",
        "        except Exception as e:\n",
        "            return jsonify({\"error\": \"Invalid image file.\"}), 400\n",
        "    else:\n",
        "        data = request.get_json(force=True)\n",
        "        if \"url\" in data:\n",
        "            response = requests.get(data[\"url\"])\n",
        "            image = tf.keras.preprocessing.image.load_img(BytesIO(response.content), target_size=IMG_SIZE)\n",
        "        elif \"file_path\" in data:\n",
        "            image = tf.keras.preprocessing.image.load_img(data[\"file_path\"], target_size=IMG_SIZE)\n",
        "        else:\n",
        "            return jsonify({\"error\": \"Provide 'url', 'file_path', or upload a file as 'file'.\"}), 400\n",
        "\n",
        "    prediction = predict_image(image)\n",
        "    return jsonify({\"prediction\": prediction})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import sys\n",
        "    # Start API server\n",
        "    if API_ENABLE:\n",
        "        ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "        public_url = ngrok.connect(5000)\n",
        "        print(\"Public URL:\", public_url)\n",
        "        app.run(host='0.0.0.0', port=5000)"
      ],
      "metadata": {
        "id": "M1PVSvtxqP39"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}